# AlignBench Developer Quickstart Guide

Welcome to AlignBench!  
This guide will help you clone, install, and contribute to the project.

---

## ðŸš€ Setup Instructions

```bash
# Clone the repository
git clone https://github.com/yourusername/AlignBench.git
cd AlignBench

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run AlignBench Benchmark
python scripts/run_alignbench.py --config configs/alignbench_config.yaml
```

## Project Structure

```bash
AlignBench/
â”œâ”€â”€ alignbench/
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ utils/
â”œâ”€â”€ configs/
â”œâ”€â”€ scripts/
â”œâ”€â”€ outputs/
â”œâ”€â”€ docs/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
```

## Developer Notes
- Model loading: ```bash alignbench/models/```
- Dataset loading: ```bash alignbench/datasets/```
- Metric computation: ```bash alignbench/evaluation/```
- Utilities: ```bash alignbench/utils/```
- Configuration: ```bash YAML files in configs/```

All modules are independent and replaceable.

---

## Troubleshooting and Common Issues

| Problem                                             | Solution                                                                                                                                                         |
| :-------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `pad_token` missing errors                          | Handled automatically inside model loading.                                                                                                                      |
| `accelerate` missing errors                         | Install via `pip install accelerate` (only needed for fast training).                                                                                            |
| Hugging Face Dataset Load Error (trust_remote_code) | Some datasets like `c4` require setting `trust_remote_code=True` while calling `load_dataset`. This is already handled inside `alignbench/datasets/load_ood.py`. |
| Permission Error on Windows Hugging Face Cache      | If using Windows, you may see warnings related to Hugging Face cache symlinks. It's safe to ignore or run Python as Administrator.                               |

---

### Important Note on Hugging Face Datasets:

Some datasets like **`c4`**, **`openwebtext`**, and other large corpora include **dynamic loading scripts**.

- Hugging Face requires **explicit permission** to trust remote loading code for these datasets.
- Therefore, AlignBench internally sets `trust_remote_code=True` when loading such datasets.

No manual action needed for users â€” already handled in AlignBench codebase.

---

# Happy Benchmarking!

Full professional Dev Guide.

Anyone can clone, run, extend your project easily now.

---

# Final Touch in `run_alignbench.py`

At the end, update your runner to use these new utilities:

```python
from alignbench.utils.metrics_format import save_metrics
from alignbench.utils.logger import info, success

...

def main(config_path):
    ...

    success(f"Fidelity Loss (FL): {fl:.4f}")
    success(f"Drift Sensitivity Index (DSI): {dsi:.4f}")
    success(f"Alignment Robustness Score (ARS): {ars:.4f}")

    # Save results
    results = {
        "Fidelity Loss (FL)": float(fl),
        "Drift Sensitivity Index (DSI)": float(dsi),
        "Alignment Robustness Score (ARS)": float(ars)
    }
    save_metrics(results, config['output_dir'])
    success(f"Benchmark Results Saved to {config['output_dir']}/benchmark_results.yaml")

```

Looks beautiful, clean, professional on console and saved YAML.
